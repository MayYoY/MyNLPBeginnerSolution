# 文本匹配

Recognizing textual entailment

输入两个句子判断，判断它们之间的关系。参考[ESIM]( https://arxiv.org/pdf/1609.06038v3.pdf)（可以只用LSTM，忽略Tree-LSTM），用双向的注意力机制实现。

1. 参考
   1. 《[神经网络与深度学习](https://nndl.github.io/)》 第7章
   2. Reasoning about Entailment with Neural Attention <https://arxiv.org/pdf/1509.06664v1.pdf>
   3. Enhanced LSTM for Natural Language Inference <https://arxiv.org/pdf/1609.06038v3.pdf>
2. 知识点：
   1. 注意力机制
   2. token2token attetnion

## Reasoning about Entailment with Neural Attention

3 类：(i) contradicting each other, (ii) not related, or whether (iii) the first sentence (called premise) entails the second sentence (called hypothesis)

LSTM + neural attention + word-by-word attention

embedding 使用冻结的 word2vec，不在 vocab 的单词采用 uniform(-0.05, 0.05) 初始化且可更新

<img src=".\LSTMreason.png" alt="LSTMreason" style="zoom:50%;" />

两个 LSTM，第二个 LSTM 的隐状态使用；输出连接一个 fc 层

加性注意力

## ESIM

<img src=".\ESIM.png" alt="ESIM" style="zoom: 67%;" />

input encoding, local inference modeling, and inference composition

两个句子 $a = (a_1,\ldots, a_{l_a}), b = (b_1, \ldots, b_{l_b})$

首先使用 BiLSTM 进行编码得到 $\bar a, \bar b$

soft alignment  $e_{i, j} = \bar a_i^T\bar b_j$

